# Testing Moodle using Provengo
This directory contains the Provengo project for testing $$*TODO* software name$$.

$$*TODO* 
1. replace the name of the folder 'helloprovengo' with the name of your software (use underscore/title case to avoid spaces)
2. Search and replace for the word 'helloprovengo' in the entire project and replace it with the new folder name. 

Done - 
in our project we changed the helloprovengo to moodle, Due to the name of the system. 
$$

## Running the tests
To run a single random test, run:
```shell 
provengo run helloprovengo
in our project we changed the helloprovengo to moodle, Due to the name of the system. so please write
provengo run moodle 
```

## Tool Documentation
See [Provengo README](moodle/README.md) for a short description of the tool and how to use it.


For a full documentation go to [https://docs.provengo.tech](https://docs.provengo.tech)

## How we created the test model:
1. We started by creating the following files: [behavior.js](moodle/spec/js/behavior.js),[actions.js](moodle/spec/js/actions.js), and [data.js](moodle/data/data.js).
2. We then ran the following command to generate the test model:
```shell
provengo analyze -f PDF moodle   
```
3. We repeated steps 1-2 until we were satisfied with the generated model.
4. We used the following command to run the tests:
```shell
provengo run --show-sessions moodle
```
5. We repeated steps 1-4 until we were satisfied with the result.
6. We recorded a video of the running tests and added it to the report. Since more than one browser session was opened, we recorded the entire screen. The link for the video is [https://drive.google.com/file/d/15pTGOagVEUSdQjnOs50p59-6d6kj8Gt6/view?usp=sharing ]($$*TODO* write the link$$).
7. We copied the generated graph of the model to a file named [model.pdf](submission-files/model.pdf) inside the submission-files directory.

### Test files
The test data is in [data.js](moodle/data/data.js), the set of possible actions is in [actions.js](moodle/spec/js/actions.js), and the behavior of the system is in [behavior.js](moodle/spec/js/behavior.js).
See the files for a detailed description.

$$*TODO*: Make sure that the text inside the files is informative, self-explanatory, and properly written (meaningful variable names, no magic number, etc.). Specifically, write for each bthread a comment that explain what it does and make sure that the bthread's name reflects its purpose. See the file for an example.$$

## How we tested the system
See the last two lessons of the [Provengo Course](https://provengo.github.io/Course/Online%20Course/0.9.5/index.html) for a detailed explanation of the following steps.

1. We implemented a domain-specific ranking function at the beginning of the [ensemble-code.js](moodle/meta-spec/ensemble-code.js) file and updated the `rankingFunction` to use our function. We added a documentation comment that explains our function.
2. We sampled the state space of the system using the following command that created a [samples.json](moodle/products/run-source/samples.json) file:
```shell
provengo sample --overwrite --size 10 moodle
```
3. Given this sample, we created an ensemble (test suite) using the following commands that created an [ensemble.json](moodle/products/run-source/ensemble.json) file:
```shell
provengo ensemble --size 5 moodle
```
4. We repeated the last two steps, changing the two size parameters, until we were satisfied with the grade of the generated test suites.
5. We copied the [ensemble.json](moodle/products/run-source/ensemble.json) file to [domain-specific.json](submission-files/domain-specific.json).
6. We visualized the specification, and highlighted the traces in the optimized test suite create by the previous command and copied the output to [domain-specific.pdf](submission-files/domain-specific.pdf).
```shell
provengo analyze -f pdf --highlight products/run-source/ensemble.json moodle
```
7. We ran the generated test suites using the following command:
```shell
provengo run -s products/run-source/ensemble.json moodle 
```
8. We generated a report of the test-suite run and looked for errors. If errors were found and the reason was a bug in the model, we fixed the model and repeated the steps 2--7. If the reason was a bug in the system, we reported the bug by filling a bug report in the [README.md](../README.md) file of the root directory of the project. The report can be generated by running the following command:
```shell
provengo report moodle
```
9. We repeated steps 1--8 for the two-way coverage criterion, where the json name of step 5 is [two-way.json](submission-files/two-way.json) and the pdf name of step 6 is [two-way.pdf](submission-files/two-way.pdf).


## ⚠️ ATTENTION - Test Configuration:
To run the tests correctly, you must select the appropriate TEST_TYPE in data.js.

* The system supports three modes:
    1. DOMAIN_SPECIFIC: Tests the basic student submission and teacher limitation flow
    2. TWO_WAY: Tests the interaction between teacher limitations and student submissions
    3. RESET: Resets the system to its initial state after running DOMAIN_SPECIFIC tests (Note: This is not a test type, but rather a system reset mechanism)

* To select a test type:
    1. Uncomment the desired TEST_TYPE line in data.js
    2. Comment out the other TEST_TYPE lines
    3. The RESET type should only be used after running DOMAIN_SPECIFIC tests

* For example:
        //let TEST_TYPE = TEST_TYPES.DOMAIN_SPECIFIC; 
        let TEST_TYPE = TEST_TYPES.TWO_WAY;  // Currently testing TWO_WAY
        //let TEST_TYPE = TEST_TYPES.RESET;